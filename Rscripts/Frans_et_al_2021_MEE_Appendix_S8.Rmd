---
title: "Appendix S8. Querying and summarising sites near current pupping locations"
author: 'Veronica F. Frans (E-mail: verofrans[-at-]gmail.com)'
date: "September 7, 2021"
output:
  html_document:
    keep_tex: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: false
    df_print: paged
  pdf_document:
    keep_tex: yes
    toc: yes
    toc_depth: 3
    fig_caption: no
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{Supporting Information}
- \fancyhead[LO,LE]{Frans et al. 2021 MEE}
- \fancyhead[RO,RE]{Integrated SDM Database}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, cache.comments = TRUE)
```

&nbsp;

This is supporting information for the *Methods in Ecology and Evolution* article entitled, **_Integrated SDM database: enhancing the relevance and utility of species distribution models in conservation management_**, by Veronica F. Frans\*, Amélie A. Augé, Jim Fyfe, Yuqian Zhang, Nathan McNally, Hendrik Edelhoff, Niko Balkenhol, & Jan O. Engler. Please contact the corresponding author (\*) for any inquiries.

# 1. Methods summary

Here, we exemplify how to use the final integrated SDM database from **Appendix S6** to query sites of interest and extract or summarise data fields across sites. We also show how to visualise these queries. In particular, we focus on sites near current New Zealand sea lion (*Phocarctos hookeri*; NZSL) pupping locations.

This script is intended for use by the database's end-users to gather further information on specific locations, or to assist in site prioritisations.

The final products from this script are as follows:

(1) Data tables (CSV format) summarising sites (mainland in general and sites near pupping locations).

(2) A map of the sites located near pupping locations and their proximity to human impact areas.

# 2. R Setup

The script presented here was done using R (version 4.0.5; R Core Team 2021) and its packages.

## 2.1. Libraries

```{r,results='hide',warning=FALSE,message=FALSE}    
# libraries
  library("raster")       # raster data
  library("rgdal")        # input/output; projections; reading ASCII files
  library("tidyverse")    # plots and working with complex tables
  library("RColorBrewer") # colours for graphics
  library("plyr")         # sort data
  library("reshape")      # sort data
  library("reshape2")     # sort data
  library("rgeos")        # polygon and point conversions
  library('tmap')         # visualizing maps
  library("cowplot")      # multiplots
  library("grid")         # multiplots
  library("png")          # display exported images in Rmarkdown
``` 

## 2.2. Directories

We create and use multiple folders to organise our inputs and outputs. Similar directories can be made anywhere by only changing the root directory object, `dir`. 

```{r, warning=FALSE,results='hide'}

# Root directory
  dir <- c('G:\\R\\NZSL_MSSDM_MCA_2019_NZ\\')

# Data directory
  dat.dir <- paste0(dir,'data')

# Intermediate data and layers
  dir.create(paste0(dir,'data\\intermediate'),recursive=TRUE)
  int.dir <- paste0(dir,'data\\intermediate')  # no '\\' here for read/writeOGR

# Intermediate layers that have been clipped
  dir.create(paste0(int.dir,'\\clipped'),recursive=TRUE)
  clp.dir <- paste0(int.dir,'\\clipped')  # no '\\' here for read/writeOGR
  
# Final layers
  dir.create(paste0(dir,'layers'),recursive=TRUE)
  lay.dir <- paste0(dir,'layers')  # no '\\' here for read/writeOGR
  
# Final tables
  dir.create(paste0(dir,'tables'),recursive=TRUE)
  tab.dir <- paste0(dir,'tables\\')

# Summary tables
  dir.create(paste0(dir,'tables\\summaries'),recursive=TRUE)
  sum.dir <- paste0(dir,'tables\\summaries\\')
  
# Final figures
  dir.create(paste0(dir,'figures'),recursive=TRUE)
  fig.dir <- paste0(dir,'figures\\')

```

## 2.3 Colours

Colourblind-friendly colours for plotting.

```{r}
# colours for state values (0-111)
  state_cols <-c('#BBBBBB','#DC050C','#882E72','#1965B0','#6195CF','#4EB265',
                 '#90C987','#F7CB45','#EE8026')

# colours for thresholds or binary plots
  thresh_cols <- c('#DDCC77','#CC3311')
  
# colours
  cat_cols <- c("#a65628","#f781bf")
  cont_cols <- c("#ff7f00","#ffff33","#377eb8","#e41a1c","#4daf4a")
  slope_cols <- c("#984ea3")
  var_cols <- c("#ff7f00", # cliff
                "#ffff33", # coast
                "#377eb8", # forest
                "#e41a1c", # grass
                "#4daf4a", # land cover
                "#984ea3", # sand
                "#a65628", # slope
                "#f781bf") # water
  
# function to explore colours for tmap:
  #tmaptools::palette_explorer()
```

## 2.4 Functions

### 2.4.1 Calculate mode

#### Calc.mode()

Calculate the mode of a categorical feature. 

```{r}
# calculate the mode of a categorical feature
  calc.mode <- function(x) {
     uniq_vals <- unique(x)
     uniq_vals[which.max(tabulate(match(x, uniq_vals)))]
  }
```

### 2.4.2 Get variable names

#### get.name()

Extract the name of an inputted variable to convert into a string and use for naming files that are saved. 

```{r}
# turn variable name into a string (for use in file naming)
  get.name <- function(x){
             y <- deparse(substitute(x))
             return(y)
  }
```

### 2.4.3 Load spatial data and ensure projection

#### get.shp()

Load points or polygons and project. The default projection is set to NZDG2000/New Zealand Transverse Mercator 2000 (EPSG: 2193).

```{r}
# load point/polygon and project
  get.shp <- function(p_name,
                      # defaults
                      polydir=dat.dir, prj=c("+init=epsg:2193")){
    # read shapefile
      pol <- readOGR(polydir, paste0(p_name))
     
    # project and return point/polygon
      pol <- spTransform(pol, CRS(paste0(prj)))
      return(pol)
  }
```

#### get.ras()

Load rasters and project. The default projection is set to NZDG2000/New Zealand Transverse Mercator 2000 (EPSG: 2193).

```{r}
# load raster and project
  get.ras <- function(r_name,
                      # defaults
                      ras_dir=dat.dir, prj=c("+init=epsg:2193")){
      # read raster
        r <- raster(paste0(ras_dir,"\\",r_name))
      
      # project and return raster
        crs(r) <- CRS(paste0(prj))
        return(r)
  }
```

# 3. Load data

Load suitable site polygons (minimum 35 females) created in **Appendix S6** under the name, *NZSL_integrated_SDM_database.shp*.

```{r, results='hide', message=FALSE}
# load and ensure projections
  sites <- get.shp('NZSL_integrated_SDM_database', polydir = lay.dir)
```

```{r}
# show column names
  colnames(sites@data)
```

Base map items for visualisation.

```{r, results='hide', message=FALSE, eval=TRUE}
# NZ polygons
  NZ_polygon <- get.shp('NZ_polygon_dissolved')

# NZ inland water bodies
  NZ_water <- get.shp('water_polygons_all_NZ')
```

Current NZSL pupping location data.

```{r, results='hide', message=FALSE}
# get shapefiles
  NZSL_current <- get.shp('current_NZSL_locations_9-20-2019',polydir = int.dir)

# keep name columns only
  NZSL_current <- (NZSL_current)[5]
  
# add column for location type
  NZSL_current$loc_type <- '1994-2019 (Dec - Mar)'
```

Human impact polygons from the multi-criteria decision analysis (MCDA).

```{r, results='hide', message=FALSE}

# load human impact areas again
  human_impact_areas <- get.shp('human_impact_areas',polydir = int.dir)

# change column name
  human_impact_areas$hum_imp <- 'human impact areas'
  
```

Planted pine forest polygons.

```{r, results='hide', message=FALSE}
# planted pine forests
  pine <- get.shp('planted_pine')

# change column name
  pine$SUBID_2016 <- 'planted pine forest'
```

# 4. Summarising all sites in the study area

First, we show how to summarise all sites, sorted by DOC (Department of Conservation) management regions and North versus South Island. 

## 4.1 How many suitable sites per DOC region and what are their average sizes?

```{r}
# summaries per region
  reg <- ddply(sites@data,.(DOC_region),
               summarize,
               count=length(site_ID), #total number of sites per region
               ttl_area=sum(area),    #total area size in km
               DOC_perc=(sum(DOC_size, na.rm=TRUE)/sum(area))*100, #% area under DOC
               mean_size=mean(area),  #mean size across region sites
               sd_size=sd(area),      #sd size across region sites
               min_size=min(area),    #minimum size across region sites
               max_size=max(area)     #maximum size across region sites
               ) %>% 
               mutate_if(is.numeric, round, digits=2) #round the outputs
# show here
   knitr::kable(reg)
```

## 4.2 How many suitable sites per main island?

```{r}
# summaries per island
  isl <- ddply(sites@data,.(main_isld),
               summarize,
               count=length(site_ID), #total number of sites per island
               ttl_area=sum(area),    #total area size in km
               DOC_perc=(sum(DOC_size, na.rm=TRUE)/sum(area))*100, #% area under DOC
               mean_size=mean(area),  #mean size across island sites
               sd_size=sd(area),      #sd size across island sites
               min_size=min(area),    #minimum size across island sites
               max_size=max(area)     #maximum size across island sites
               ) %>% 
               mutate_if(is.numeric, round, digits=2) #round the outputs
# show here
   knitr::kable(isl)
```

## 4.3 How certain are we of the site predictions?

Here, we can summarise the range of uncertainty for each state prediction.

```{r, warning=FALSE}
# summaries for sites near historic locations
  cv.sum <- ddply(sites@data,.(),
                  summarize,
                  mean_S1=mean(S1_uncrt), #mean CV across island sites
                  mean_S2=mean(S2_uncrt), #mean CV across island sites
                  mean_S3=mean(S3_uncrt), #mean CV across island sites
                  sd_S1=sd(S1_uncrt),     #sd CV across island sites
                  sd_S2=sd(S2_uncrt),     #sd CV across island sites
                  sd_S3=sd(S3_uncrt),     #sd CV across island sites                  
                  min_S1=min(S1_uncrt),   #minimum CV across island sites
                  min_S2=min(S2_uncrt),   #minimum CV across island sites
                  min_S3=min(S3_uncrt),   #minimum CV across island sites
                  max_S1=max(S1_uncrt),   #maximum CV across island sites
                  max_S2=max(S2_uncrt),   #maximum CV across island sites
                  max_S3=max(S3_uncrt)    #maximum CV across island sites 
                  ) %>% 
                   mutate_if(is.numeric, round, digits=2) #round the outputs
# transform
  cv.sum <- melt(cv.sum)
  cv.sum <- cv.sum[,-1]
  colnames(cv.sum)[2] <- 'CV_percent'
  
# show here
  knitr::kable(cv.sum)
  
```

## 4.4 How many sites per region are within 10km of current/historic pupping locations?

```{r}
# summaries per region
  cur_hist <- ddply(sites@data,.(DOC_region),
                   summarize,
                   ttl_curr=sum(!is.na(curr_NZSL)), #number sites within curr.
                   ttl_hist=sum(!is.na(histr_NZSL)), #number sites within hist.
                   perc_curr=sum(!is.na(curr_NZSL))/
                             length(site_ID), #% sites within current breeding locations
                   perc_hist=sum(!is.na(histr_NZSL))/
                             length(site_ID) #% sites within historical breeding locs
                   ) %>% 
                   mutate_if(is.numeric, round, digits=2) #round the outputs

# show here
   knitr::kable(cur_hist)
```


# 5. Extract sites within 10km of current NZSL pupping sightings and summarise

Only select sites where the column *curr_NZSL* has data (not NA).

```{r}
# subset the sites within current pupping location ranges
  sites_curr_loc <- sites[!is.na(sites@data$curr_NZSL),]
```

From this, we can then make the following short queries:

```{r}
# how many sites?
  length(sites_curr_loc)
  
# list names of sites
  select(sites_curr_loc@data, DOC_region, site_ID)
```

## 5.1 How many sites are near each pupping location?

Since the *curr_NZSL* column is a semi-colon-separated (;) list of multiple pupping site location names, we first separate them into duplicate rows. Then we summarise by pupping location.

```{r}
# split into mulple rows
  curr_long <- separate_rows(sites_curr_loc@data, curr_NZSL, sep = "; ",
                            convert = TRUE)

# convert to factor
  curr_long$curr_NZSL <- as.factor(curr_long$curr_NZSL)
  
# summaries of pupping locations
  pup <- ddply(curr_long,.(curr_NZSL),
               summarize,
               ttl_curr=length(curr_NZSL)  #number sites within curr.
               )
# show here
  knitr::kable(pup)
```

This table can also be viewed as a bar chart.

```{r}
# colours
  colourCount = length(unique(pup$curr_NZSL))
  getPalette = colorRampPalette(brewer.pal(9, "Spectral"))
  
# plot site frequencies per pupping location
  freq_sites <- ggplot(pup) + 
                aes(x=curr_NZSL, y=ttl_curr, fill=factor(curr_NZSL)) + 
                geom_bar(stat='identity') +
                scale_fill_manual(values = getPalette(colourCount)) +
                ylab('count') + xlab('current pupping locations') +
                ggtitle('Number of sites within 10km of known pupping locations') +
                theme(axis.text.x=element_text(angle = 45, vjust = .9, hjust = .9),
                      legend.position = 'none')

# display here
  freq_sites
```

## 5.2 Quick map

Here is a quick view of the sites.

```{r}
# plot sites
  plot(sites_curr_loc)
```

A better way to plot these sites is shown in the next section.

# 6. Mapping the sites

## 6.1 Base map

Get extent of current NZSL pupping locations, which will be used for the map.

```{r}
# get extent
  extent(sites_curr_loc)
```

Create a background polygon that is clipped to this area. We use the above extent to first create a raster and then a polygon.

```{r, eval=TRUE}
# create background polygon
  bkg <- as(raster::extent(c(1190875,1454325,4758650,4956625)), "SpatialPolygons")
  proj4string(bkg) <- paste0("+init=epsg:2193 +proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996",
                             " +x_0=1600000 +y_0=10000000 +ellps=GRS80 ",
                             "+towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
  bkg <- spTransform(bkg, CRS("+init=epsg:2193"))
```

Make a base map with the background polygon as the extent, and the NZ and inland water polygons as the overlain layers.

```{r, eval=TRUE}
# set mode
  tmap_mode("plot")

# base map
  # background polygon
    bkg_map <- tm_shape(bkg) +
               tm_borders('white', alpha = 0) +
               tm_layout(frame=FALSE, bg.color = NA)
  
  # NZ polygon
    NZ_map <- tm_shape(NZ_polygon) + 
              tm_polygons(col='#DDDDDD', border.alpha = 0) +
              tm_legend(show=FALSE)
    
  # inland water bodies
    wtr_map <- tm_shape(NZ_water) +
               tm_fill(col='#33BBEE',
                       palette = '#33BBEE', alpha = 1) +
               tm_legend(show=FALSE)
    
  # combine
    base_map <- bkg_map + NZ_map + wtr_map
```

We can view the base map here.

```{r}
# display here
  base_map
```

## 6.2 Human impact polygons

Make a map layer of human impact area polygons.

```{r, eval=TRUE}
# human impact areas
  hum_map <- tm_shape(human_impact_areas) +
             tm_fill(col='hum_imp',
                     palette='#EE7733',alpha = 1,
                     title = '', legend.show = FALSE)
```

We can view it here, lain over the base map. 

```{r}
# display here
  base_map + hum_map
```

## 6.3 Sites and current pupping locations

Make a map layer of suitable sites polygons.

```{r, eval=TRUE}
# make suitable sites polygon layers
  suit_map <- tm_shape(sites_curr_loc) +
              tm_polygons(border.col='#000000', lwd=1, alpha = 0, border.alpha = 1,
                          title = 'suitable sites', legend.show = FALSE)
```

Make a map layer of current pupping locations.

```{r, eval=TRUE}
# points for current sighting locations
  nzsl_pts <- tm_shape(NZSL_current) +
              tm_dots(col = 'loc_type', size = 0.08,
                      palette=c('#882E72'), shape = 17,
                      title = 'known female/pup locations', legend.show = FALSE)
```

## 6.4 Legend

Create legend of all the objects.

```{r, eval=TRUE}
# legend only
  leg <- bkg_map +
        # suitable sites
          tm_add_legend(type = c("symbol"),
                  labels = 'Suitable sites',
                  col = '#000000',
                  size = .5, shape = 0,
                  title = '') +
        # NZSL sightings
          tm_add_legend(type = c("symbol"),
                  labels = 'Current pupping sites',
                  col = '#882E72',#'#33BBEE',
                  size = .3, shape = 17,#19,
                  title = '') +
        # human impacts
          tm_add_legend(type = c("symbol"),
                labels = 'Human impact areas',
                col = '#EE7733',#'#EE6677',
                alpha = 1,
                size = .5, shape = 15,
                title = '') +
        # inland water bodies
          tm_add_legend(type = c("symbol"),
                labels = 'Inland water bodies',
                col = '#33BBEE',
                alpha = 1,
                size = .5, shape = 15,
                title = '') +
        # layout
          tm_layout(legend.show = TRUE,
                   legend.position = c('right','bottom'),
                   frame=FALSE,
                   bg.color = NA)
```

## 6.5 Combined map

Combine all map layers and legend into one map.

```{r, eval=TRUE}
site_map <- # maps
            base_map + hum_map + nzsl_pts + suit_map + 
            # legend
            leg +
            # scalebar
            tm_scale_bar(breaks = c(0,10,20), size = 0.5,
                           position = c(.4,0))
```

Save map.

```{r}
# save image ("plot" mode)
  tmap_save(site_map, filename = paste0(fig.dir,"current_sites_zoom.png"),
            height = 4, width=5, units = 'in', dpi=600)
```

Display here.

```{r echo=TRUE, out.width='100%'}
knitr::include_graphics(paste0(fig.dir,"current_sites_zoom.png"))
```

# 7. Subsetted data table of the sites

Make a new dataframe of certain columns within the database and extract as a CSV table (these were used for Table 2 in the corresponding manuscript).

```{r}
# dataframe select by column
  curr_df <- select(sites_curr_loc@data,
                    c(site_ID, # site name information
                      area,    # site size information
                      DOC_pc,  # existing management information
                      hum_im_pc, graze_pc, fences,     # human impacts
                      S1_limits, S2_limits, S3_limits, # restoration features
                      MESS_class, dissim_var,          # model uncertainty
                      S1_uncrt, S2_uncrt, S3_uncrt
                      ))

# change NAs to 0
  curr_df$DOC_pc[is.na(curr_df$DOC_pc)] <- 0
  curr_df$graze_pc[is.na(curr_df$graze_pc)] <- 0
```

Change some of the data inside to compress the table.

```{r}
# Change names
  curr_df$fences <- mapvalues(curr_df$fences, 
                              from=c('absent','present'),
                              to=c('N','Y'))
# Remove words
  curr_df <- data.frame(lapply(curr_df,
                               function(x) {gsub(" distance","",x,ignore.case = TRUE)}))
  curr_df <- data.frame(lapply(curr_df,
                               function(x) {gsub("inland ","",x,ignore.case = TRUE)}))
  curr_df <- data.frame(lapply(curr_df,
                               function(x) {gsub("land cover","LC",x,ignore.case = TRUE)}))
```

\blandscape

```{r}
# inspect final table
   knitr::kable(curr_df)
```

Save as CSV.

```{r}
# save as csv
  write.csv(curr_df,paste0(tab.dir,'evaluation_sites_FORMATTED.csv'), row.names = FALSE)
```

# 8. Save workspace

```{r,cache=TRUE,cache.comments=FALSE}
# save workspace to load later if needed
  save.image("G:/R/sites_eval.RData")
```

\elandscape
